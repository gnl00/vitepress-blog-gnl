# MySQL

<br>

## MySQL 体系架构

由上至下分为：网络连接层，服务层，存储引擎层，系统文件层。

![image-20220209150005366](./assets/image-20220209150005366.png)

<br>

### 网络连接层/客户端连接

Connectors，提供给各种应用程序（JDBC、ODBC）接入 MySQL 服务的接口。客户端与服务端建立连接，客户端发送 SQL 语句到服务端执行。

<br>

### 服务层

1、**管理服务和工具组件**，系统管理和控制工具，如备份恢复、安全管理、MySQL 复制、集群管理等

2、**连接池**

- 由于每次建立连接需要消耗很多时间，连接器的作用就是将这些连接缓存下来，下次可以直接用已经建立好的连接，提升服务器性能
- 主要负责连接管理、授权认证等。每个客户端连接都对应着服务器上的一个线程，服务器上维护可一个线程池，避免为每个连接都创建销毁一个线程。当客户端连接到 MySQL 服务器时，服务器对其进行认证，可以通过用户名和密码进行认证，也可以通过 SSL 证书进行认证。登录认证后，服务器还会验证的客户端角色是否有执行某个查询的操作权限

3、**SQL 接口**，接收客户端发送过来的 SQL 命令，并返回操作结果

- **DDL**（Data Definition Language），DDL 允许用户定义数据，也就是创建表、删除表、修改表结构这些操作。通常，DDL 由数据库管理员执行（主要面向DBA）
- **DML**（Data Manipulation（操纵） Language），DML 为用户提供添加、删除、更新数据的能力，这些是应用程序对数据库的日常操作（主要面向开发者）
- **DQL**（Data Query Language），DQL 允许用户查询数据，这也是通常最频繁的数据库日常操作（主要面向用户）

4、**查询解析器**

- SQL 命令传递到解析器的时候会被解析器**验证和解析**
- `<mark>`MySQL 是一个 DBMS（数据库管理系统），无法直接理解 SQL 语句，查询解析器负责对 SQL 语句进行验证和解析，让 DBMS 知道下一步该做什么`</mark>`

5、**查询优化器**

- SQL 语句在查询之前会使用查询优化器对查询进行优化，查询优化器使用的是**选取、投影、联接**策略进行查询，以此选择一个最优的查询路径

  ```sql
  select uid, name from user where uid = "1";
  ```

  1. select 查询先根据 where 语句进行选取，而不是先全表查询后再进行条件过滤
  2. select 查询先根据 uid 和 name 进行属性投影，而不是将属性全部取出来后再进行过滤
  3. 将这两个查询条件联接起来，生成最终查询结果

6、**缓存**

- 缓存和缓冲组件，查询缓存，如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中读取数据
- 需要注意的是在 MySQL 的 8.0 版本以后，缓存被官方删除掉了。因为查询缓存的失效非常频繁，如果在一个写多读少的环境中，缓存会频繁的新增和失效。对于某些更新压力大的数据库来说，查询缓存的命中率会非常低，MySQL 为了维护缓存可能会出现一定的伸缩性的问题。目前在 5.6 的版本中已经默认关闭了，比较推荐的一种做法是将缓存放在客户端，性能大概会提升 5 倍左右
- MySQL 缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key 缓存，权限缓存等

<br>

### 存储引擎层

> MySQL 中的数据用各种不同的技术存储在文件（内存）中。每一种技术都使用不同的存储机制、索引技巧、锁方式，并且提供不同操作数据的功能和能力。通过选择不同的技术，能够获得不同的速度或者功能，从而改善应用的整体功能。 这些不同的技术以及配套的相关功能在 MySQL 中被称作**存储引擎**，也称作**表类型**

**细节**

- **`<mark>`存储引擎的概念是 MySQL 里面才有的`</mark>`，不是所有的关系型数据库都有存储引擎这个概念**。MySQL 区别于其他数据库最重要的一个特点就是，`<mark>`插件式的**表存储引擎**`</mark>`。需要注意：**存储引擎是基于表的**
- MySQL 采用插件式的存储引擎，提供了多种存储引擎，每种存储引擎有不同的特点。可以根据不同的业务特点，选择合适的存储引擎
- 负责数据的存储和读取，与数据库文件打交道。服务器中的查询执行引擎通过 API 与存储引擎进行通信，通过接口屏蔽了不同存储引擎之间的差异

<br>

**查询 MySQL 存储引擎**

```sql
show engines;
```

<br>

**常见存储引擎**

1、**InnoDB**，`<mark>`默认事务型存储引擎`</mark>`

- 它被设计用来处理大量的短期（short-lived）事务，除非有特别的原因，否则应该优先考虑 InnoDB引 擎
- `<mark>`提供了具有提交，回滚和崩溃回复能力的事务安全`</mark>`
- `<mark>`行级锁，并发能力强，适合高并发操作`</mark>`
- `<mark>`支持自动增长列，支持外键约束，默认使用 B+ 树数据结构存储索引`</mark>`
- 对于使用 InnoDB 的表，其数据的物理组织形式是**聚簇表**。所有的数据按照主键来组织，数据和索引放在一起，都位于 B+ 树的叶子结点上
- 存在缓冲管理，通过缓冲池，将索引和数据全部缓存起来，加快查询的速度

  读数据，会首先从缓冲池中读取，若是没有则从磁盘读取再放入缓冲池；写数据，会首先写入缓冲池，再定期同步到磁盘上
- 占用空间是 MyISAM 的2.5倍，处理效率相对会差一些
- InnoDB 不保存表的具体行数，执行 ` select count(*) from table` 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可

<br>

2、**MyISAM**，拥有较高的插入，查询速度

- 提供了包括全文索引（B+ 树数据结构存储索引），空间函数（GIS）等特性
- `<mark>`不支持事务`</mark>`，崩溃后无法安全恢复，以 `select`、`insert`为主的应用基本上使用这个引擎
- `<mark>`全表锁，拥有较快的执行速度，并发性能差`</mark>`
- `<mark>`不支持外键，使用B+ 树数据结构存储索引`</mark>`
- 占用空间相对较 InnoDB 小

<br>

3、**Memory**

- 所有数据置于内存的存储引擎，拥有极高的插入，更新和查询效率。所有数据存储在内存中，速度快，但会占用与数据量成正比的内存空间，且数据在 MySQL 重启时会丢失
- 全表锁
- 默认使用 Hash 索引，检索效率非常高，主要用于内容变化不频繁且数据量较小的表

<br>

4、Archive

- Archive 档案存储引擎只支持 `insert`和 `select`操作，在 MySQL 5.1 之前不支持
- 适合日志和数据采集类应用
- 特点是占用空间小，Archive 表比 MyISAM 表小约 75%，比 InnoDB 表小约 83%

<br>

5、CSV

- CSV 引擎可以将普通的 CSV 文件作为 MySQL 表来处理，但不支持索引
- CSV 存储的数据可以在操作系统里用文本编辑器或 Excel 打开
- CSV 引擎可以作为一种数据交换机制

<br>

6、Merge，一组 MyISAM 表的组合，在超大规模数据存储时很有用

<br>

> 一张表，里面有ID自增主键，当 insert 了 17 条记录之后，删除了第 15，16，17 条记录，把 MySQL 重启，再 insert 一条记录，这条记录的 ID 是 18 还是 15 ？

如果表的存储引擎类型是 MyISAM，那么是 18。因为 MyISAM 表会把自增主键的最大 ID 记录到数据文件中，重启 MySQL 自增主键的最大 ID 也不会丢失；

如果表的存储引擎类型是 InnoDB，那么是 15。因为 InnoDB 表只是把自增主键的最大 ID 记录到内存中，所以重启数据库或对表进行 OPTION 操作，都会导致最大 ID 丢失。

> 哪个存储引擎执行 `select count(*)`更快?

MyISAM 更快，因为 MyISAM 内部维护了一个计数器，可以直接调取。在 MyISAM 存储引擎中，把表的总行数存储在磁盘上，当执行 `select count(*)`时，直接返回总数据。

InnoDB 跟 MyISAM 不一样，没有将总行数存储在磁盘上，当执行 `select count(*)`时，会先把数据读出来，一行一行的累加，最后返回总数量。所以当数据越来越大时，InnoDB 执行该语句就越来越耗时。这跟 InnoDB 的事务特性有关，由于多版本并发控制（MVCC）的原因，InnoDB 表**应该返回多少行**也是不确定的。

<br>

### 系统文件层

系统文件层主要是将数据库的数据存储在文件系统中，并完成与存储引擎的交互。其存储的文件主要有：日志文件、数据文件、配置文件、MySQL 的进程 pid 文件和 socket 文件等。

1 - **日志文件**

1、错误日志（Error log），默认开启，`show variables like '%log_error%;'`

2、通用查询日志（General query log），记录一般查询语句，`show variables like '%general%';`

3、二进制日志（Binary log），[MySQL Binlog 介绍](https://blog.csdn.net/wwwdc1012/article/details/88373440)

记录了对 MySQL 数据库执行的更改操作，并且记录了语句的发生时间、执行时长；但是它不记录 `select、show` 等不修改数据库的 SQL，主要用于数据库恢复和主从复制。

```shell
# 是否开启
show variables like '%log_bin%';
# 参数查看
show variables like '%binlog%'; 
# 查看日志文件
show binary logs;
```

4、慢查询日志（Slow query log）

记录所有执行时间超时的查询SQL，默认是10秒。

```shell
# 是否开启
show variables like '%slow_query%';
# 时长
show variables like '%long_query_time%';
```

5、中继日志，中继日志也是二进制日志，用来给 slave 库做恢复

6、事务日志，redo log 和 undo log

2 - **配置文件**，用于存放 MySQL 所有的配置信息文件，比如 `my.cnf`、`my.ini`等。

3 - **数据文件**

- `<mark>`不同的存储引擎，存储在文件系统中的数据文件格式不同`</mark>`

  1、MyISAM

  - `*.frm`，与表相关的元数据信息都存放在 frm 文件中，包括表结构的定义信息等
  - `*.MYD`，MyISAM Data，用于存储 MyISAM 表的数据，每一张 MyISAM 表对应一个 MYD 文件
  - `*.MYI`，MyISAM Index，用于存储 MyISAM 表的索引相关信息，每一张 MyISAM 表对应一个 MYI 文件

  2、InnoDB

  - `*.frm`，与表相关的元数据信息都存放在 frm 文件中，包括表结构的定义信息等
  - `*.ibd`，InnoDB Data，存储表数据和索引的文件。该表的索引（B+ 树）的每个非叶子结点存储索引，叶子结点存储索引与索引对应的数据
  - `*.ibdata`，存储内容与 `*.ibd`相同

    InnoDB 的数据存储方式能够**通过配置来决定是使用共享表空间存放存储数据，还是独享表空间存放存储数据**。独享表空间存储方式使用 `*.ibd`，并且每个表为一个 ibd 文件。共享表空间存储方式采用 ibdata 文件，即所有的表共同使用一个 ibdata 文件

    决定使用哪种表的存储方式可以通过 MySQL 的配置文件中的 `innodb_file_per_table`选项来指定。InnoDB 默认使用的是独享表的存储方式，这种方式的好处是当数据库产生大量文件碎片的时候，整理磁盘碎片对线上运行环境的影响较小

4 - **pid 文件**

pid 文件是 mysqld 应用程序在 Unix/Linux 环境下的一个进程文件，和许多其他 Unix/Linux 服务端程序一样，它存放着自己的进程 id。

5 - **socket 文件**

socket 文件也是在 Unix/Linux 环境下才有的，用户在 Unix/Linux 环境下客户端连接可以不通过TCP/IP 网络而直接使用 Unix Socket 来连接 MySQL。

<br>

## SQL 执行流程

<img src="./assets/image-20210407205445602.png" alt="image-20210407205445602" style="zoom: 80%;" />

1、客户端通过**连接器**（JDBC、ODBC），将 **SQL 语句发送**到 MySQL 服务器；

2、客户端与 MySQL 服务器**建立连接**，MySQL 服务器验证请求的用户名和密码是否正确，账户正确；在系统表中验证用户权限，验证通过，进行下一步，验证不通过则报错；

3、命中**缓存**，从缓存中取结果返回；未命中缓存，继续下一步，进入 SQL 查询解析器；

4、**查询解析器**对 SQL 语句进行解析，包括预处理和解析过程。在这个阶段会对 SQL 语句进行关键词和非关键词提取、解析，组成一棵解析树。

关键字如：`select/update/in/or/where/group by`等，如果分析到语法错误，报错 `ERROR: You have an error in your SQL syntax`。同时也会对 SQL 语句做一些验证，如：表是否存在，字段是否存在等；

5、在查询之前，使用**查询优化器**对查询进行优化，查询优化器使用的是“选取、投影、联接”策略进行查询，如：将 SQL 语句中的查询条件调换位置，为让底层能使用索引，选择一个最优的查询路径

6、**执行器**，调用存储引擎对应的 API，根据 SQL 语句对数据文件进行操作，执行完成之后，将具体操作保存到 bin log 中（select操作除外）。

7、返回结果




<br>

## 索引

> 索引，是关系数据库中对某一列或多个列的值进行预排序的**数据结构**

<br>

### 关于索引

```sql
-- 创建索引的基本语法
CREATE INDEX indexName ON table(column(length));
-- 参数 length 默认可以忽略
CREATE INDEX idx_name ON user(name);
```

**细节**

- `<mark>`在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式指向数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构就是索引，**索引的本质是一种数据结构**`</mark>`
- 通过使用索引，可以让数据库系统不必扫描整个表，而是直接定位到符合条件的记录，这样就大大加快了查询速度
- 索引是建立在数据库表中的某些列的上面。因此在创建索引的时候，应该仔细考虑在哪些列上可以创建索引，在哪些列上不能创建索引

**优点**

- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性
- 索引减小了服务器需要扫描的数据量，加快数据的查询速度，这也是创建索引的最主要的原因
- 索引可以将随机 IO 变成顺序 IO

**缺点**

- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加
- 索引需要占物理空间，除了数据表占用数据空间之外，每一个索引还要占用一定的物理空间，如果需要建立聚簇索引，那么需要占用的空间会更大
- 对表中的数据进行增、删、改的时候，索引也要动态的维护，这就降低了整数的维护速度

<br>

### 索引结构

#### B TREE（B 树）

> B 树中所有结点孩子结点个数的最大值称为 B 树的阶，通常用 **m** 表示，从查找效率考虑，要求 **m >= 3**

**细节**

一颗 **m** 阶的 B 树要么是一颗**空树**，要么是满足以下要求的 **m 叉树**：

- `<mark>`每个结点最多有 **m** 个分支（子树）`</mark>`
- 最少分支的结点要看是否为根结点：如果是根结点且不是叶子结点，则至少有两个分支；非根非叶结点至少有 **[m/2]** 个分支（ **[a]** 是对 **a** 向上取整，即不小于 **a** 的最小整数）
- **k=2**（根结点）或 **k=[m/2]** （非根结点），有 **n**（`k<=n<=m`）个分支的结点有 **n-1** 个关键字，关键字按照递增顺序排序。

**结点结构**

<img src="./assets/image-20210409193229683.png" alt="image-20210409193229683"  />

- **n** 为结点中关键字的个数
- **k`<sub>`i`</sub>`** 为结点的关键字且满足 **k`<sub>`i`</sub>`<k`<sub>`i+1`</sub>`**
- **p`<sub>`i`</sub>`**（`0<=i<=n`）为指向孩子结点指针，且满足 **p`<sub>`i`</sub>`**（`1<=i<=n-1`）所指结点上的关键字大于 **k`<sub>`i`</sub>`** 且小于 **k`<sub>`i+1`</sub>`**，**p`<sub>`0 `</sub>`** 所指结点上的关键字小于 **k`<sub>`1`</sub>`**，且 **p`<sub>`n `</sub>`**所指结点上的关键字大于 **k`<sub>`n`</sub>`**
- 结点内关键字互不相等且按从小到大排序
- 叶子结点处于同一层，可以用空指针表示，是查找失败到达的位置

![image-20220210141850639](./assets/image-20220210141850639.png)

**B树特征**

- 在 B 树中，具有 **n** 个关键字的结点含有 **n+1** 个分支
- 关键字集合分布在整棵树中
- 任何一个关键字出现且只出现在一个结点中
- 搜索有可能在非叶子结点结束
- 搜索性能等价于在关键字全集内做一次二分查找
- 自动层次控制（平衡控制）

B 树的查找，是多路查找，从根结点开始，对结点内的关键字（递增排序）序列进行二分查找，如果命中则结束。否则进入查询关键字所属范围的孩子结点，并重复二分查找，直到遍历到的结点为空（查找失败），或者命中

> ⚠ 平衡 **m** 叉查找树是指每个关键字的左子树和右子树高度差绝对值不超过 1 的查找树，其结点结构与 B 树结点结构相同。因此可认为 B 树是平衡 **m** 叉查找树，但限制更强，要求把所有叶子结点放在同一层

<br>

#### B+TREE（B+树）

> B+ Tree 是基于 B-Tree 和叶子结点顺序访问指针进行实现

**细节**

- 根且非叶子结点的孩子结点数为 **[2, m]**
- 非根非叶结点的孩子结点数为 **[m/2, m]**
- 在 B+ 树中，具有 **n** 个关键字的结点含有 **n** 个分支；而在 B 树中，具有 **n** 个关键字的结点含有 **n+1** 个分支
- 在 B+ 树中，每个结点（非根结点）中的关键字个数 **n** 的取值范围为 `[m/2]<=n<=m`，根结点取值范围为 `2<=n<=m`；而在 B 树中，它们的取值范围分别是 `[m/2]-1<=n<=m-1`和 `1<=n<=m-1`
- 在 B+ 树中叶子结点包含信息，并且包含全部关键字，叶子结点的指针指向**记录**
- B+ 树中的所有非叶子结点仅仅起到了一个索引的作用（作为叶子结点的索引），即结点中的每个索引项只含有对应子树的最大关键字和指向该字数的指针
- 在 B+ 树上有一个指针指向关键字最小的叶子结点，所有叶子结点连接成一个双向线性链表，而 B 树没有
- B+ 树的搜索与 B 树也基本相同，区别是 B+ 树只有达到叶子结点才命中（B 树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找
- B+ 树是自底向上插入的，优先会将数据插入到叶子节点中，然后整个树会根据底部的叶子节点进行变动

<br>

**B+ 树特征**

- 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字是有序的
- 查找操作不会在非叶子结点命中
- 非叶子结点相当于叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层
- 每一个叶子结点都包含一个指向下一个叶子结点的指针，从而方便叶子结点的范围遍历
- 更适合文件索引系统

![image-20210522195820218](./assets/image-20210522195820218.png)

<br>

#### B+ 树与 B 树索引对比

1. B+ 树的`<mark>`磁盘读写代价更低`</mark>`

   B+ 树的数据都集中在叶子结点，分支结点只作为索引存在；B 树的分支结点既有指针也有数据。相较于 B 树，B+ 树每个非叶子结点存储的关键字数更多，导致 B+ 树的层次会低于 B 树，也就是说 B+ 树平均的 IO 次数会小于 B 树
2. B+ 树的`<mark>`查询效率更加稳定`</mark>`

   B+ 树的数据都存放在叶子结点，因此任何关键字的查找必须走一条从根结点到叶子结点的路径，所有结点的查询路径相同，每个数据查询效率相当
3. B+ 树`<mark>`更便于遍历`</mark>`

   由于 B+ 树的数据都存储在叶子结点中，分支结点均为索引，遍历只需要扫描一遍叶子结点即可；B 树因为其分支结点同样存储着数据，要找到具体的数据，需要进行一次中序遍历按序来搜索。简单来说就是，B+ 树需要遍历有序链表，而 B 树需要对整颗树进行中序遍历
4. B+ 树`<mark>`更擅长范围查询`</mark>`

   B+ 树叶子结点存放数据，数据是按照顺序放置的双向链表。B 树范围查询只能中序遍历
5. B+ 树`<mark>`占用内存空间小`</mark>`

   B+ 树索引结点没有数据，比较小。在内存有限的情况下，相比于 B 树索引可以加载更多 B+ 树索引

**推荐使用自增 id 而不是 uuid 或者身份证号等**

叶子结点链表会根据当前最后一条的位置，将最新的一条数据顺序的插入到后面

![image-20210522201305456](./assets/image-20210522201305456.png)

但是当你插入一个 uuid 时，MySQL 根本不知道他该插入到哪个位置，需要从头开始寻找插入的位置。当我们的插入的页满了时，这就造成了页的分裂和合并，极大的影响了效率

![image-20210522201351202](./assets/image-20210522201351202.png)

而且我们使用 uuid 的话，uuid 所占字节也比较长，就导致了每一页存储的数据就会变少，也不利于索引的数据查询

<br>

#### HASH（哈希）

> 哈希索引就是采用一定的哈希算法，把存储的键的哈希指算出来，**使用哈希值代替键值存储**，检索时不需要类似 B+ 树一样从根结点到叶子结点逐级查找，只需要执行一次哈希算法就可定位到相应的位置，速度非常快。Memory 存储引擎使用的就是 Hash 索引

**细节**

- `<mark>`Hash 索引就是将索引字段进行 hash 存储，整个 hash 索引的结构是 Hash 表 + 链表（因为会存在 hash 冲突）`</mark>`
- 哈希索引仅仅能满足 `=`、`in`和 `<=>`（`<=>`类似 `=`，和 `=`运算符不同的是，NULL 的值是没有任何意义的。所以 `=`号运算符不能把 NULL 作为有效的结果。此时可以使用 `<=>`）查询，不能使用范围查询（大于小于），也不支持任何范围查询
- 由于哈希索引比较的是进行哈希运算后的 Hash 值，所以 Hash 索引适合精确查找，但是范围查找不适合

**哈希和 B+ 树的区别**

- 如果是等值查询，哈希索引占有绝对优势，因为只需要经过一次算法就可找到相应的键值；前提是所有的键值都是唯一的，如果键值不唯一，就需处理哈希冲突
- 如果是范围查询，B+ 树占绝对优势，因为原先是有序的键值，经过哈希算法后，就可能变成不连续了，就没有办法再利用索引完成范围查询
- B+ 树索引的关键字检索效率比较平均，不像 B 树那样波动幅度大。在有大量重复键值情况下，哈希索引因为存在哈希碰撞，效率也是极低的
- 哈希索引没有办法利用索引完成排序，以及 `like`这样的迷糊查询（`like`本质上也是范围查询）
- 哈希不支持多列联合索引的左右匹配规则

<br>

### 索引分类

> 逻辑分类和物理分类

#### 逻辑分类

1、**功能划分**

1）**主键索引**，一张表只能有一个主键索引，不允许重复、不允许为 NULL

```sql
ALTER TABLE TableName ADD PRIMARY KEY(column_list); 
```

2）**唯一索引**，数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，但是一个唯一索引只能包含一列，比如身份证号码、卡号等都可以作为唯一索引

```sql
CREATE UNIQUE INDEX IndexName ON `TableName`(`字段名`(length));
# 或
ALTER TABLE TableName ADD UNIQUE (column_list); 
```

3）**普通索引**，一张表可以创建多个普通索引，一个普通索引可以包含多个字段，允许数据重复，允许 NULL 值插入

```sql
CREATE INDEX IndexName ON `TableName`(`字段名`(length));
# 或
ALTER TABLE TableName ADD INDEX IndexName(`字段名`(length));
```

4）**全文索引**，查找的是文本中的关键词，主要用于全文检索。它用于替代效率较低的 LIKE 模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。使用的数据结构是 B 树。

5）**空间索引**

空间索引是对空间数据类型的字段建立的索引，MySQL 中的空间数据类型有 4 种，分别是 `GEOMETRY、POINT、LINESTRING、POLYGON`。

MySQL 使用 `SPATIAL`关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。

```sql
CREATE TABLE `gim` (
  `path` varchar(512) NOT NULL,
  `box` geometry NOT NULL,
  PRIMARY KEY (`path`),
  SPATIAL KEY `box` (`box`)
) ;
```

* **创建空间索引的列，必须将其声明为 `NOT NULL`**
* **空间索引只能在存储引擎为 MYISAM 的表中创建**。

2、**按列划分**

1）**单列索引**，一个索引只包含一个列，一个表可以有多个单例索引

2）**组合索引/复合索引**，一个组合索引包含多个列。`<mark>`查询的时候遵循 MySQL组合索引的**最左前缀**原则`</mark>`，从左到右匹配，即`<mark>`**查询条件要包含建立索引时最左边的字段**`</mark>`，索引才会生效。

```sql
-- 创建索引的基本语法
CREATE  INDEX indexName ON table(column1(length),column2(length));
-- 例子 
CREATE INDEX idx_phone_name ON user(phone,name);
```

<br>

**最左前缀匹配原则**

首先基于建立一个联合索引

```sql
CREATE INDEX idx_age_height_weight ON user(age, height, weight)
```

我们已经了解了索引的数据结构是一颗 B+ 树，也了解了 B+ 树优化查询效率的其中一个因素就是对数据进行了排序，那么我们在创建 `idx_age_height_weight`这个索引的时候，也就相当于创建了一颗 B+ 树索引，而这个索引就是**依据联合索引的成员来进行排序**，这里是 `age、height、weight`

- `idx_age_height_weight` 这个索引会根据 `age、height、weight`进行排序

InnoDB 中只要有主键被定义，主键列会被作为一个聚簇索引，而其它索引都将被作为非聚簇索引，所以 `idx_age_height_weight`这个索引就会是一个非聚簇索引

- `idx_age_height_weight` 这个索引是一个非聚簇索引，查询时需要回表

在 MySQL 中，联合索引的排序有这么一个原则，从左往右依次比较大小，就拿刚才建立的索引举例子，会先去比较 age 的大小，如果 age 的大小相同，那么比较 height 的大小，如果 height 也无法比较大小， 那么就比较 weight 的大小，`<mark>`若是无法进行排序比较大小的列，就无法走联合索引`</mark>`

**例子**

```sql
create index idx_phone_name on user_innodb(phone, name);

-- 1
SELECT * FROM user_innodb where name = 'zs';
-- 2
SELECT * FROM user_innodb where phone = '1234567890';
-- 3
SELECT * FROM user_innodb where phone = '1234567890' and name = 'zs';
-- 4
SELECT * FROM user_innodb where name = 'zs' and phone = '1234567890';
```

三条 SQL 只有 `2、3、4`能使用的到索引 `idx_phone_name`，因为条件里面必须包含索引前面的字段才能够进行匹配。

> 3 和 4 相比 where 条件的顺序不一样，为什么 4 可以用到索引呢？

是因为在执行 SQL 之前，经过服务层的 SQL 查询解析器 SQL 优化器，会对 SQL 语句进行优化，会根据 SQL 来识别出来该用哪个索引，我们可以理解为 3 和 4 在 MySQL 眼中是等价的

**最左匹配特点**

1、最左前缀匹配原则，MySQL 会一直向右匹配直到遇到范围查询（`>、<、between、like`）就停止匹配，比如 `a=3 and b=4 and c>5 and d=6`，如果建立（`a, b, c, d`）顺序的索引，**d** 是无法使用索引的，如果建立（`a, b, d, c`）的索引则都可以使用到，`a、b、d`的顺序可以任意调整

2、`=`和 `in`可以乱序，比如 `a=1 and b=2 and c=3`建立（`a, b, c`）索引可以任意顺序，MySQL 的查询优化器会帮你优化成索引可以识别的形式

<br>

#### 物理分类

1、**聚簇索引/主索引（Clustered Index）**

**主键目录**

每个数据页中，必然就有一个最小的主键，每个数据页的页号和最小的主键会组成一个**主键目录**。假设现在要查找主键为 2 的数据，通过二分查找法最后确定下主键为 2 的记录在数据页 1 中，此时就会定位到数据页 1 接着再去定位主键为 2 的记录

![image-20220210155810732](./assets/image-20220210155810732.png)

**索引页**

> 假设有1000万条记录、5000万条记录呢？是不是就算是二分法查找，其效率也依旧是很低的，所以为了解决这种问题 MySQL 又设计出了一种新的存储结构**索引页**

![image-20220210160158772](./assets/image-20220210160158772.png)

假设主键目录中的记录是非常非常多的，MySQL 会将里面的记录拆分到不同的索引页中

![image-20220210160250772](./assets/image-20220210160250772.png)

索引页中记录的是每页数据页的页号和该数据页中最小的主键的记录，也就是说最小主键和数据页号不是单纯的维护在主键目录中了，而是演变成了索引页，索引页和数据页类似，一张不够存就分裂到下一张。

像这种**索引页+数据页**组成的组成的 B+ 树就是**聚簇索引**。

![Snipaste_2022-02-10_21-06-00](./assets/Snipaste_2022-02-10_21-06-00.png)

**聚簇索引特性**

- `<mark>`**B+ 树叶子结点中包含数据表中行记录的话就是聚簇索引，即索引和数据是一体的**`</mark>`
- `<mark>`聚簇索引也可理解为将数据存储与索引放到了一块，找到索引也就找到了数据`</mark>`
- 聚簇索引就是按照每张表的主键构造一颗 B+ 树。同时叶子结点中存放的就是整张表的行记录数据，也将聚集索引的叶子结点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引
- 叶子结点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以**一个表只能有一个聚簇索引**。

**优点**

1）数据访问更快，因为聚簇索引将索引和数据保存在同一个 B+ 树中，因此从聚簇索引中获取数据比非聚簇索引更快

2）聚簇索引对于主键的排序查找和范围查找速度非常快

**缺点**

1）插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于 InnoDB 表，一般都会定义一个自增的 ID 列为主键（主键列不要选没有意义的自增列，选经常查询的条件列才好，不然无法体现其主键索引性能）

2）更新主键的代价很高，因为将会导致被更新的行移动。因此，对于 InnoDB 表，一般定义主键为不可更新

3）**二级索引**访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

<br>

2、**非聚簇索引**（辅助索引/二级索引）

- `<mark>`B+ 树叶子结点中没包含数据表中行记录的话就是非聚簇索引，即索引和数据是分开的`</mark>`
- 叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到聚簇索引中进行查找。**一个表可以存在多个非聚簇索引**
- 辅助索引叶子结点存储的不再是行数据记录，而是主键值。首先通过辅助索引找到主键值，然后到主键索引树中通过主键值找到数据行，这个过程称为**回表**

![image-20210522200620369](./assets/image-20210522200620369.png)

<br>

3、**覆盖索引**（Covering Index），或者叫索引覆盖， 也就是平时所说的不需要回表操作

索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据，当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含（覆盖）满足查询结果的数据就叫做覆盖索引。

`select`的数据列只用从索引中就能够取得，不必读取数据行，MySQL 可以利用索引返回 `select`列表中的字段，而不必根据索引再次读取数据文件，换句话说**查询列要被所建的索引覆盖**。

<br>

### 不同存储引擎索引

**InnoDB**，主键索引是聚簇索引，辅助索使用的是非聚簇索引

- InnoDB 中主键不宜定义太大，因为辅助索引也会包含主键列。如果主键定义的比较大，其他索引也将很大。如果想在表上定义很多索引，应该尽量把主键定义得小一些。**InnoDB 不会压缩索引**
- **InnoDB 表必须要有主键，并且推荐使用整型自增主键**。InnoDB 中尽量不使用非单调（递增或者递减）字段作主键，因为 InnoDB 数据文件本身是一颗 B+ 树，非单调的主键会造成在插入新记录时数据文件为了维持 B+ 树的特性而频繁的分裂调整，十分低效。而使用自增字段作为主键则是一个很好的选择

**MyISAM**，非聚簇索引，MyISAM 主索引和辅助索引都是非聚簇索引

<br>

### 索引创建时机

**何时创建索引**

- `<mark>`作为主键的列`</mark>`上，强制该列的唯一性和组织表中数据的排列结构
- `<mark>`经常需要查询的列`</mark>`
- `<mark>`经常用在连接（JOIN）的列`</mark>`上，外键字段建立索引，使用索引可以加快连接的速度
- `<mark>`经常需要根据范围（<，<=，=，>，>=，BETWEEN，IN）进行搜索的列`</mark>`上创建索引，因为索引已经排序，其指定的范围是连续的
- `<mark>`经常需要排序（order by）的列`</mark>`上创建索引，因为索引已经排序，查询可以利用索引的排序，加快排序查询时间
- 查询中需要统计或者分组的列
- `<mark>`经常使用在 WHERE 子句中的列`</mark>`上面创建索引，加快条件的判断速度
- 尽量选择区分度高的列作为索引，公式：`count(distinct(column_name)) : count(*)`。可以简单地计算出这个字段的离散值，离散值越高，说明建立索引效果更明显。例如给手机号加索引，最后计算出来的离散度是 1，说明非常有必要加索引

**不需创建索引**

- 对于那些在查询中很少使用或者参考的列不应该创建索引

  若列很少使用到，有索引或无索引，并不能提高查询速度。增加了索引，反而降低了系统的维护速度和增大了空间需求
- 对于那些只有很少数据值或者重复值多的列也不应该增加索引

  这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度
- 对于那些定义为 `text`，`image `，`bit`数据类型的列不应该增加索引

  这些列的数据量要么相当大，要么取值很少
- 经常增删改的表，经常需要更新的列，不应该创建索引

<br>

### 索引失效场景

1、全表扫描的查询索引失效

2、查询时带有 `is null`条件的语句，会进行全表扫描，无法利用索引。因为索引的结构是有序的，遇到 `null`值时无法确定它的位置。解决办法是将 `null`值转换为其他值，如 0

3、前导模糊查询不能利用索引，比如 `%like`和 `%like%`

4、查询带有 `or`关键字不走索引，除非将 `or`条件中的所有列都创建索引

5、如果是组合索引，未遵循最左匹配原则不会走索引。比如创建索引 `idx_name_age_phone`，查询语句为 `select * from table where age = 20 and phone = 12345678;`，跳过最左边的列，不走索引

6、如果全表扫描比走索引快，不会走索引

7、使用不等于条件 `!=`或者 `<>`会导致全表扫描

8、在索引列上做任何操作，如计算，使用函数，类型转换（自动或者手动）等操作会导致索引失效而进行全表扫描

<br>

## 事务

> 事务，是指一组 SQL 语句的集合，集合中的 SQL 语句可能是 insert、update、select、delete，这些 SQL 语句的执行是一致的，作为一个整体执行，我们希望这些多个 SQL 语句都能成功执行或者都失败

<br>

### 特性

> 四个特性，ACID

1、**原子性**（Atomicity）

事务要么全部提交成功，要么全部失败回滚，不能只执行其中一部分操作

2、**一致性**（Consistency）

- 操作前后总量不变，事务的执行不能破坏数据库的完整性和一致性，一个事务在执行之前和执行之后，数据库必须处于一致性状态
- 如果数据库系统在运行过程中发生故障，有些事务尚未完成就被迫中断，这些未完成的事务对数据库所做的修改已有一部分写入物理数据库，这时数据库就处于一种不正确的状态，也就是不一致的状态

3、**隔离性**（Isolation）

在并发环境中，并发的事务是相互隔离的，一个事务的执行不能被其他事务干扰。不同的事务并发操作相同的数据时，每个事务内部的操作及使用的数据对其他事务是隔离的，并发执行的各个事务之间互不干扰

4、**持久性**（Durability）

- 事务提交之后，数据发生的变化是永久的
- 一旦事务提交，它对数据库中对应数据的变更就会永久保存到数据库中，即使发生系统崩溃或者服务器宕机等故障，只要数据库能够重新启动，就能将其恢复到事务成功的状态

<br>

### 隔离级别

**查看当前隔离级别**

```sql
show variables like 'tx_isolation';
```

<br>

**并发事务带来的问题**

|            | 概念                                                                                                                                                                             | 产生时机  | 解决办法                                                                                                                                                                                                                                                                                |
| ---------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 脏读       | 一个事务正在访问数据，并对数据进行了修改，修改还没有提交到数据库中，此时另一个事务也访问这个数据，并且读取到了数据，读取到了脏数据                                               | 修改      | 1、加锁，在读取数据前，对其加锁，阻止其他事务对数据进行修改<br />2、MVVC 加版本号，不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本 |
| 不可重复读 | 在一个事务内，多次读同一数据，得到的是不一样的结果。事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。 | 修改      | 同上                                                                                                                                                                                                                                                                                    |
| 幻读       | 一个事务 A 读取了几行数据，接着另一个并发事务 B 插入了一些数据时。在随后的查询中，事务 A 就会发现多了一些原本不存在的记录，或者记录少了，就好像发生了幻觉一样，所以称为幻读。    | 新增/删除 | 同上                                                                                                                                                                                                                                                                                    |

<br>

**隔离级别**

1、**读未提交**（Read Uncommitted）

- 隔离级别最低，存在脏读、不可重复读、幻读

2、**读已提交**（Read Committed）

- 读已提交只允许获取已经提交的数据，解决脏读，存在不可重复读、幻读
- ==不可重复读的重点是修改==。同样的条件，读取过的数据，再次读取出来发现值不一样

3、**可重复读**（Repeatable Read），MySQL 默认隔离级别为可重复读

- 可重复读就是保证在事务处理过程中，多次读取同一个数据时，其结果和事务开始时刻读取到的值是一致的。解决脏读和不可重复读，存在幻读
- ==幻读的重点在于新增或者删除==。同样的条件，第 1 次和第 2 次读出来的记录数不一样

4、**串行化**

* 最严格的事务隔离级别，它要求所有事务被串行化，即事务只能一个接着一个进行处理，不能并发执行。脏读、不可重复读、幻读都不会出现

<br>

**各隔离级别对比**

| 隔离级别 | 读数据一致性                             | 脏读 | 不可重复读 | 幻读 |
| -------- | ---------------------------------------- | ---- | ---------- | ---- |
| 读未提交 | 最低级别，只能保证不读取物理上损坏的数据 | ✔   | ✔         | ✔   |
| 读已提交 | 语句级                                   | ✖   | ✔         | ✔   |
| 可重复读 | 事务级                                   | ✖   | ✖         | ✔   |
| 串行化   | 最高级别，事务级                         | ✖   | ✖         | ✖   |

<br>

### 事务的实现

<br>

#### 读写锁

> 共享锁，称为读锁；排他锁，称为写锁

- 读锁是可以共享的，多个读请求可以共享一把锁读数据，不会造成阻塞
- 写锁会排斥其他所有获取锁的请求，会一直阻塞，直到写操作完成，释放锁资源
- `<mark>`通过读写锁可以做到读读并行，但是不能做到读写或者写写并行`</mark>`
- **实现可重复读**

<br>

#### Redo Log 事务日志

> 重做日志，用来**实现事务的持久性**。分为两部分：重做日志缓冲（redo log buffer）和重做日志文件（redo log），重做日志缓冲在内存中，重做日志文件在磁盘中。**当事务提交之后会把所有修改信息都存放到 redo log 中**

- MySQL 为了提升性能不会每次都把修改操作实时同步到磁盘中，而是会先将修改操作放到缓冲池中，即**重做日志缓冲**，之后再使用后台线程去做缓冲池与磁盘之间的同步
- 如果在同步之前发生了宕机，就会丢失部分已提交事务的修改信息。所以使用 redo log 来记录已成功提交事务的修改信息，并且把 redo log 文件持久化到磁盘上，系统重启之后再读取 redo log 恢复最新数据
- `<mark>`redo log 是用来恢复数据的，用于保障已提交事务的持久化特性`</mark>`

<br>

#### Undo Log 事务日志

> 回滚日志，用于记录数据被修改前的信息。与 redo log 相反，重做日志记录数据被修改后的信息，回滚日志主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚，是**实现事务的原子性**

- MySQL 每次写入数据或者修改数据之前都会把修改信息记录到 undo log 中
- 每条数据表更（`insert/update/delete`）操作都伴随着一条 undo log 的生成，并且必须`<mark>`先将修改信息记录到回滚日志，再将数据持久化到磁盘上`</mark>`。为何？因为有缓冲池的存在，不用同步持久化，可以异步持久化。先将数据保存到缓冲池中，再将缓冲池中的数据定期保存到磁盘中，降低磁盘 IO 频率，提高性能。
- undo log 记录事务修改之前版本的数据信息，因此如果系统出现错误或者执行 rollback 操作的话，可以根据 undo log 的信息来进行回滚，回到修改前的状态。即根据回滚日志做逆向操作，`insert `逆向为 `delete`，`update `还是 `update`，`delete `变 `insert`
- `<mark>`undo log 是用来回滚数据的，用于保障事务的原子性`</mark>`

<br>

#### MVCC 多版本并发控制

> MySQL 的大多数事务型存储引擎实现都不是简单的行级锁。基于提升并发性考虑，一般都同时实现了多版本并发控制（MVCC），包括 Oracle、PostgreSQL。只是实现机制各不相同。典型的 MVCC 实现方式，分为**乐观（optimistic）并发控制和悲观（pressimistic）并发控制**。

`MultiVersion Concurrency Control`，多版本并发控制，通过在每行记录的后面保存两个隐藏的列来实现的。两个列中，一个保存了行的创建时间，一个保存了行的过期时间。当然存储的并不是真实的时间，而是系统版本号（System Version Number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。

MVCC 的实现是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。

保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。

**MVCC 只在 COMMITTED READ（读已提交）和 REPEATABLE READ（可重复读）两种隔离级别下工作。**

MVCC 在 MySQL 中的实现需要依赖 undo log 和 read view：

* undo log，记录某行记录的多个版本的数据
* read view，用来判断当前版本数据的可见性

- `<mark>`事务的隔离性是通过读写锁 + MVCC 来实现的`</mark>`
- `<mark>`事物的一致性是通过持久性 + 原子性 + 隔离性来实现的`</mark>`

### 分布式事务

> 分布式事务的实现方式有很多，既可以采用 InnoDB 提供的原生的事务支持，也可以采用消息队列来实现分布式事务的最终一致性。

MySQL 从 5.0.3 InnoDB 存储引擎开始支持 XA 协议的分布式事务。一个分布式事务会涉及多个行动，这些行动本身是事务性的。所有行动都必须一起成功完成，或者一起被回滚。在 MySQL 中，使用分布式事务涉及一个或多个**资源管理器**和一个**事务管理器**。

![image-20220211141428327](./assets/image-20220211141428327.png)

如图，MySQL 的分布式事务模型。模型中分三块：应用程序（AP）、资源管理器（RM）、事务管理器（TM）:

- 应用程序：定义了事务的边界，指定需要做哪些事务；
- 资源管理器：提供了访问事务的方法，通常一个数据库就是一个资源管理器；
- 事务管理器：协调参与了全局事务中的各个事务。

分布式事务采用**两段式提交（two-phase commit）**的方式：

- 第一阶段所有的事务节点开始准备，告诉事务管理器 ready。
- 第二阶段事务管理器告诉每个节点是 commit 还是 rollback。如果有一个节点失败，就需要全局的节点全部 rollback，以此保障事务的原子性。

<br>

## SQL 规范

1、尽量避免进行全表扫描

2、不要超过三张表关联

3、表字段不宜过多，对太多字段的表进行拆分

4、尽量不使用 `select *`

5、适当建立索引，但是不能建立过多索引

6、根据不同的功能使用不同的存储引擎，插入、查询较多则使用 MyISAM，支持事务使用 InnoDB

7、尽量避免大段的事务操作

<br>

> `count(*)`和 ` count(1)`和 `count(列名)`区别

执行效果上：

- `count(*)`包括了所有的列，相当于行数，在统计结果的时候，**不会忽略列值为 NULL**
- `count(1)`包括了所有列，用 1 代表代码行，在统计结果的时候，**不会忽略列值为 NULL**
- `count(列名)`只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者 0，而是表示 null ）的计数，即**某个字段值为 NULL 时，不统计。**

执行效率上：

- 列名为主键，`count(主键)`会比 `count(1)`快
- 列名不为主键，`count(1)`会比 `count(列名)`快
- 如果表多个列并且没有主键，则 `count(1)`的执行效率优于 `count(*)`
- 如果有主键，则 `select count（主键）`的执行效率是最优的
- 如果表只有一个字段，则 `select count(*)`最优。

<br>

> `UNION`和 `UNION ALL`的区别?

* `UNION`在进行表连接后会筛选掉重复的数据记录（效率较低），而 `UNION ALL`则不会去掉重复的数据记录；
* `UNION`会按照字段的顺序进行排序，而 `UNION ALL`只是简单的将两个结果合并就返回；

<br>

> `in`和 `exists`的区别？

* `exists`对外表用 `loop`逐条查询，每次查询都会查看 `exists`的条件语句。当 `exists`里的条件语句能够返回记录行时（无论记录行是的多少，只要能返回），条件就为真，返回当前 `loop`到的这条记录；反之，如果 `exists`里的条件语句不能返回记录行，则当前 `loop`到的这条记录被丢弃，`exists`的条件就像一个 `bool`条件，当能返回结果集则为 `true`，不能返回结果集则为 `false`
* `in`查询相当于多个 `or`条件的叠加
* **如果查询的两个表大小相当，那么用 `in`和 `exists`差别不大**；如果两个表中一个较小，一个是大表，则子查询表大的用 `exists`，子查询表小的用 `in`

<br>

## MySQL 数据存储

### 数据存储位置

1、**磁盘**

从磁盘上读写数据，至少需要两次 IO 请求才能完成。

一次是读 IO，另一次是写 IO。而 IO 请求是比较耗时的操作，如果频繁的进行 IO 请求会影响数据库的性能。

**2、寄存器**

操作系统从寄存器中读取数据是最快的，因为它离 CPU 最近。但是寄存器只能存储非常少量的数据，设计它的目的主要是用来暂存指令和地址，并非存储大量用户数据的。

**3、内存**

内存同样能满足快速读取和写入数据的需求，而且性能非常可观，只是比较寄存器稍稍慢了一些。不过内存相对于磁盘来说，成本更加昂贵。因此一般只使用内存存储一部分用户数据。而非全部数据。

此外，即使用户数据能刚好存在内存，若是数据库服务器或者部署节点宕机，或者重启了，数据就会丢失。

> 如何存储数据才能不会因为异常情况而丢数据，同时又能保证数据的读写速度？MySQL 的 InnoDB 存储引擎使用**数据页**来进行数据存储

### 数据页

**页**是 InnoDB 中**管理数据的最小单元**。InnoDB 内存的两个主要区域分别为 **Buffer Pool** 和 **Log Buffer**，此处的 Log Buffer 是用于缓存 **Redo Log** 的，而 Buffer Pool 则是 InnoDB 中，十分重要、核心的一部分，位于主存。

**Buffer Pool**

MySQL 中的很多的操作都是发生在内存，再从内存将文件保存到磁盘上，可使用的内存大小就决定操作效率高低。

由于缓存的数据类型和数据量非常多，Buffer Pool 存储的时候一定会按照某些结构去存储，并且做了某些处理。否则获取的时候除了遍历所有数据之外，没有其他的捷径，这样的低效率操作肯定是无法支撑 MySQL 的高性能的。**因此，Buffer Pool 被分成了很多页，每页可以存放很多数据。**

InnoDB 使用了**链表**来组织页和页中存储的数据，页与页之间形成了**双向链表**，这样可以方便的从当前页跳到下一页，同时使用 LRU（Least Recently Used）算法去淘汰那些不经常使用的数据。

![image-20220209143322448](./assets/image-20220209143322448.png)

同时，每页中的数据也通过**单向链表**进行链接。因为这些数据是分散到 Buffer Pool 中的，单向链表将这些分散的内存给连接了起来。

![image-20220209143313364](./assets/image-20220209143313364.png)

到这里可能有一个疑问，用户记录里是单链表。最坏的情况下，需要的数据可能在链表末端，此时查询数据就比较低效。为了解决这个问题，MySQL 又在页中加入了另一个区域 `Page Directory` 。

<img src="./assets/image-20220209164327501.png" alt="image-20220209164327501" />

顾名思义，`Page Directory` 是个目录，里面有很多个**槽位（Slots）**，每一个槽位都指向了一条 `User Records` 中的记录。并且每隔几条数据，就会创建一个槽位。在一个完整的页中，**每隔6条数据就会有一个 Slot。**

MySQL 会在新增数据的时候就将对应的 Slot 创建好，有了 `Page Directory` ，就可以对一张页的数据进行粗略的**二分查找**。至于为什么是粗略，毕竟 `Page Directory` 中不是完整的数据，二分查找出来的结果只能是个大概的位置，找到了这个大概的位置之后，还需要回到 `User Records` 中继续的进行挨个遍历匹配。

![image-20220209164453734](./assets/image-20220209164453734.png)

**Log Buffer**

Log Buffer 用来存储那些即将被刷入到磁盘文件中的日志，例如 Redo Log，该区域也是 InnoDB 内存的重要组成部分。Log Buffer 的默认值为 16M，如果我们需要进行调整的话，可以通过配置参数 `innodb_log_buffer_size`来进行调整。

如果 Log Buffer 较大，就可以存储更多的 Redo Log，这样一来在事务提交之前我们就不需要将 Redo Log 刷入磁盘，只需要丢到 Log Buffer 中去即可。因此较大的 Log Buffer 就可以更好的支持较大的事务运行；同理，如果有事务会大量的更新、插入或者删除行，那么适当的增大 Log Buffer 的大小，也可以有效的减少部分磁盘 I/O 操作。

至于 Log Buffer 中的数据刷入到磁盘的频率，则可以通过参数 `innodb_flush_log_at_trx_commit`来决定。

**数据页操作**

1、**写操作**

进行写操作时，可以把一批数据放在一起，先将数据写到内存的某个批次中，然后再将该批次的数据一次性刷到磁盘上。

<img src="./assets/写操作.jpeg" alt="写操作" style="zoom: 67%;" />

2、**读操作**

读操作时，从磁盘上一次读一批数据，然后加载到内存当中，以后就在内存中操作。

<img src="./assets/读操作.jpeg" alt="读操作" style="zoom:67%;" />

> 将内存中的数据刷到磁盘，或者将磁盘中的数据加载到内存，都是以批次为单位，这个批次就是我们常说的：`数据页`。InnoDB 中存在多种不同类型的页，数据页只是其中一种。

数据页主要是用来存储表中记录的，它在磁盘中是用双向链表相连的，方便查找，能够非常快速得从一个数据页，定位到另一个数据页。

若是表中的数据比较多，在磁盘中可能存放在多个数据页当中。我们要根据某个条件查询数据时，需要从一个数据页找到另一个数据页，这时候的双向链表就派上大用场了。磁盘中各数据页的整体结构如下图所示：

<img src="./assets/image-20211124104015806.png" alt="image-20211124104015806" style="zoom: 33%;" />

通常情况下，单个数据页默认的大小是 `16kb`。也可以通过参数：`innodb_page_size`，来重新设置大小。一般情况下，用它的默认值就够了。

#### 数据页结构

<img src="./assets/image-20211124104031229.png" alt="image-20211124104031229" style="zoom: 33%;" />

从上图中可以看出，数据页主要包含如下几个部分：文件头部、页头部、最大和最小记录、用户记录、空闲空间、页目录、文件尾部。

1、**文件头部**

它里面包含了多个信息，其中4个最关键的信息：页号、上一页页号、下一页页号、页类型。

InnoDB 是通过页号、上一页页号和下一页页号来串联不同数据页的。如下图所示：

<img src="./assets/image-20211124104251227.png" alt="image-20211124104251227" style="zoom: 33%;" />

不同的数据页之间，通过上一页页号和下一页页号构成了**双向链表**。这样就能从前向后，一页页查找所有的数据了。

**页类型**也是一个非常重要的字段，它包含了多种类型，其中有：数据页、索引页（目录项页）、溢出页、undo 日志页等。

2、**页头部**

通过文件头部包含的多个信息，数据页之间能够轻松访问。

> 在操作数据页的时候我们通常会需要数据页的信息，比如一页数据到底保存了多条记录，页目录到底使用了多个槽等，就是记录的状态信息。这些信息如何记录，保存到哪里？

MySQL 为了性能考虑，上面的这些统计数据，是先统计好的，再保存到页头部。后面需要用到该数据时，再读取出来。

页头部记录了：已删除记录所占的字节数、最后插入记录的位置、最大事务 id、索引 id、索引层级

3、**最大和最小记录**

<img src="./assets/最大和最小记录.jpeg" alt="最大和最小记录" style="zoom: 50%;" />

MySQL 在保存用户记录的同时，数据库会自动创建两条额外的记录：最大记录 Supremum 和 最小记录 Infimum。

在一个数据页中，如果存在多条用户记录，从最小记录开始通过 `下一条记录的位置`相连，一直到最大纪录为止。

<img src="./assets/image-20220209163559367.png" alt="image-20220209163559367" style="zoom: 80%;" />

有了 `Infimum Record` 和 `Supremum Record` ，现在查询不需要将某一页的 `User Records` 全部遍历完，只需要将这两个记录和待查询的目标记录进行比较。比如，要查询的数据 `id = 101` ，那很明显不在当前页。接下来就可以通过**下一页指针**跳到下页进行检索。

4、**用户记录**

对于新申请的数据页，用户记录是空的。当插入数据时，innodb 会将一部分 `空闲空间`分配给用户记录。

innodb 支持的用户记录数据行格式为：compact 行格式、redundant 行格式、dynamic 行格式、compressed 行格式

以 compact 行格式为例：

![image-20211124104139424](./assets/image-20211124104139424.png)

一条用户记录主要包含三部分内容：

1. 记录额外信息，它包含了变长字段、null 值列表和记录头信息。
2. 隐藏列，它包含了行 id、事务 id 和回滚点。
3. 真正的数据列，包含真正的用户数据，可以有很多列。

**额外信息**

> 额外信息并非真正的用户数据，它是为了辅助存数据用的。

1）变长字段列表

有些数据如果直接存会有问题，比如：如果某个字段是 varchar 或 text 类型，它的长度不固定，可以根据存入数据的长度不同，而随之变化。

如果不记录数据真正的长度，innodb 不知道要分配多少空间。假如都按某个固定长度分配空间，但实际数据又没占多少空间，就会造成空间利用的浪费。所以需要在变长字段中记录某个变长字段占用的字节数，方便按需分配空间。

2）null 值列表

数据库中有些字段的值允许为 null，如果把每个字段的 null 值，都保存到用户记录中，显然有些浪费存储空间。

> 有没有办法只简单的标记一下，不存储实际的 null 值呢？

将为 null 的字段保存到 null 值列表。在列表中用二进制的值1，表示该字段允许为 null，用0表示不允许为 null。它只占用了1位，就能表示某个字符是否为 null，可以节省很多存储空间。

3）记录头信息

记录头信息用于描述一些特殊的属性。

![image-20211124104406690](./assets/image-20211124104406690.png)

它主要包含：

- deleted_flag，删除标记，用于标记该记录是否被删除了。
- min_rec_flag，最小目录标记，它是非叶子节点中的最小目录标记。
- n_owned，拥有的记录数，记录该组索引记录的条数。
- heap_no，堆上的位置，它表示当前记录在堆上的位置。
- record_type，记录类型，其中：0表示普通记录，1表示非叶子节点，2表示Infrimum记录， 3表示Supremum记录。
- next_record，下一条记录的位置。

**隐藏列**

数据库在保存一条用户记录时，会自动创建一些隐藏列。如下图所示：

<img src="./assets/image-20211124104430681.png" alt="image-20211124104430681" style="zoom:50%;" />

目前 innodb 自动创建的隐藏列有三种：

1）db_row_id，行id，它是一条记录的唯一标识。

如果表中有主键，则用主键做行id，无需额外创建。如果表中没有主键，假如有不为 null 的 unique 唯一键，则用它做为行 id，同样无需额外创建。如果表中既没有主键，又没有唯一键，则数据库会自动创建行 id。在 innodb中，隐藏列中 `事务id`和 `回滚点`是一定会被创建的，但行 id 要根据实际情况决定。

2）db_trx_id，事务id，它是事务的唯一标识。

3）db_roll_ptr，回滚点，它用于事务回滚。

**真正数据列**

真正的数据列中存储了用户的真实数据，它可以包含很多列的数据。

**用户记录是如何相连的？**

`记录额外信息 ==> 记录头信息 ==>下一条记录的位置`

<img src="./assets/用户记录.png" alt="用户记录" style="zoom:50%;" />

多条用户记录之间通过 `下一条记录的位置`，组成了一个单向链表。这样就能从前往后，找到所有的记录

5、**空闲空间**

最开始的时候用户记录是空的，当插入数据的时候就会向空闲空间中申请空间，当空闲空间没有空间了，则说明需要申请新的页

6、**页目录 Page Directory**

> Page Directory 在上文已经做过介绍，此处不再赘述。

7、**文件尾部**

> 文件尾部主要是为了防止页在刷入磁盘的过程中，由于极端的意外情况（网络问题、火灾、自然灾害）导致失败，而造成数据不一致的情况，也就是说形成了**脏页**

数据库的数据是以数据页为单位，加载到内存中，如果数据有更新的话，需要刷新到磁盘上。如果某一天，程序在刷新到磁盘的过程中出现了异常，比如：进程被 kill 掉了，或者服务器被重启了。这时候数据可能只刷新了一部分，如何判断上次刷盘的数据是完整的呢？这就需要用到 `文件尾部`。它里面记录了页面的 `校验和`。

**在数据刷新到磁盘之前，会先计算一个页面的校验和。后面如果数据有更新的话，会计算一个新值。**文件头部也会记录这个校验和，由于文件头部在前面，会先被刷新到磁盘上。

刷新页数据到磁盘的时候，假设刷新了一部分，恰好程序出现异常了。这时文件尾部的校验和，还是一个旧值。数据库会去校验，文件尾部的校验和，不等于文件头部的新值，说明该数据页的数据是不完整的。

## MySQL 主从库配置

**主库写入，从库读取**

使用 Docker 版本 mysql:5.7.28

1、新建启动 master 库

```shell
docker run -d --name mysql-master -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /mydata/mysql/master/log:/var/log/mysql -v /mydata/mysql/master/data:/var/lib/mysql -v /mydata/mysql/master/conf:/etc/mysql mysql:5.7.28
```

2、在 `/mydata/mysql/master/conf`目录下编辑 `my.cnf`，加入以下内容

```shell
[client]
default-character-set=utf8

[mysql]
default-character-set=utf8

[mysqld]
init_connect='SET collation_connection = utf8_unicode_ci'
init_connect='SET NAMES utf8'
character-set-server=utf8
collation-server=utf8_unicode_ci
skip-character-set-client-handshake
#skip-name-resolve    为了加快和mysql数据库的连接速度
skip-name-resolve

#设置服务id
server_id=1
#开启binlog
log-bin=mysql-bin
#关闭只读模式-->master可写
read-only=0
#设置别的MySQL同步的库
binlog-do-db=gmall_ums
binlog-do-db=gmall_pms
binlog-do-db=gmall_oms
binlog-do-db=gmall_sms
binlog-do-db=gmall_cms

#设置别的MySQL忽略同步的库
replicate-ignore-db=mysql
replicate-ignore-db=sys
replicate-ignore-db=information_schema
replicate-ignore-db=performance_schema
```

3、重启 master 镜像

4、新建启动 slaver 库

```shell
docker run -d --name mysql-slaver-01 -p 3316:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /mydata/mysql/slaver/log:/var/log/mysql -v /mydata/mysql/slaver/data:/var/lib/mysql -v /mydata/mysql/slaver/conf:/etc/mysql mysql:5.7.28
```

5、同样新建编辑 slaver 的 `my.cnf`

```shell
[client]
default-character-set=utf8

[mysql]
default-character-set=utf8

[mysqld]
init_connect='SET collation_connection = utf8_unicode_ci'
init_connect='SET NAMES utf8'
character-set-server=utf8
collation-server=utf8_unicode_ci
skip-character-set-client-handshake
skip-name-resolve

server_id=2
log-bin=mysql-bin
#从库仅只读
read-only=1
#设置需要同步或者忽略库
binlog-do-db=gmall_ums
binlog-do-db=gmall_pms
binlog-do-db=gmall_oms
binlog-do-db=gmall_sms
binlog-do-db=gmall_cms


replicate-ignore-db=mysql
replicate-ignore-db=sys
replicate-ignore-db=information_schema
replicate-ignore-db=performance_schema
```

6、启动 MySQL，进入 MySQL 容器内部

1）授权 root 可以远程访问（ 主从都要配置，为了方便我们远程连接 MySQL ）

访问账号 root，密码 123456

```shell
grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option;

flush privileges;
```

2）主库配置添加用来同步的用户

在主库给从库分配一个连接主库的账号密码、账号名 backup，密码 123456

```shell
GRANT REPLICATION SLAVE ON *.* to 'backup'@'%' identified by '123456';
```

3）查看 master 状态

```
show master status；
```

3-1）查看完整状态

```shell
show master status\G;
```

4）从库设置主库连接

从库使用主库分配的账号密码连接主库

```shell
change master to master_host='121.43.124.80',master_user='backup',master_password='123456',master_log_file='mysql-bin.000001',master_log_pos=0,master_port=3306;
```

5）启动从库开始同步

```shell
start slave;
```

 6）查看从库状态

```shell
  show slave status\G;
```

使用 MyCat 或者在项目中引入 Sharding-JDBC 依赖让项目读取到主从数据库

```xml
<!-- https://mvnrepository.com/artifact/io.shardingjdbc/sharding-jdbc-core -->
<dependency>
    <groupId>io.shardingjdbc</groupId>
    <artifactId>sharding-jdbc-core</artifactId>
    <version>2.0.3</version>
</dependency>
```

<br>

## 参考

https://juejin.cn/post/6850037271233331208

https://juejin.cn/post/6950462246476578829

https://juejin.cn/post/6976060490506043423

https://juejin.cn/post/6931901822231642125

https://blog.csdn.net/wwwdc1012/article/details/88373440

https://blog.csdn.net/wangfeijiu/article/details/113409719

https://blog.csdn.net/wangfeijiu/article/details/112454405

https://segmentfault.com/a/1190000021464570
